# word2vec Schritt für Schritt

**Schriftliche Arbeit zum [CAS Big Data und Machine Learning der Universität Zürich](http://www.ifi.uzh.ch/de/studies/cas.html)**

Thomas Briner, thomas.briner@gmail.com

## Abstract

Mit der Veröffentlichung von word2vec änderte sich ab 2013 die Ausgangslage im Gebiet des Natural Language Processing (NLP) grundsätzlich. Die Resultate von word2vec übertrafen die bisherigen Ansätze bezüglich der Qualität wie auch der Performance deutlich. Das Grundprinzip von word2vec, dass basierend auf einem Kontext die passenden Wörter vorausgesagt werden, ist ausgesprochen einleuchtend und intuitiv. Wieso  dies aber zu Word Embeddings führt, die sowohl für semantische als auch syntaktische Problemstellungen hervorragende Resultate erzielen, ist überraschend. In dieser Arbeit wird die Funktionsweise von word2vec Schritt für Schritt durchleuchtet und anhand eines konkreten Beispiels greifbar gemacht.


## PDF Dokument

Das Dokument ist hier verfügbar: [word2vec_Schritt_fuer_Schritt.pdf](https://github.com/thomasbriner/word2vec-Schritt-fuer-Schritt/raw/master/word2vec_Schritt_fuer_Schritt.pdf)
<a href="https://github.com/thomasbriner/word2vec-Schritt-fuer-Schritt/raw/master/word2vec_Schritt_fuer_Schritt.pdf">
<img src="https://github.com/thomasbriner/word2vec-Schritt-fuer-Schritt/blob/master/images/pdf_icon.jpg" width="300" height="418" title="PDF Dokument">
</a>



## Beispiel
Die zugrundeliegenden Berechnungen für das Beispiel sind folgendermassen zugänglich:
- Jupyter Notebook als Read-only und zum Download
<a href="https://github.com/thomasbriner/word2vec-Schritt-fuer-Schritt/raw/master/word2vec_Schritt_fuer_Schritt.pdf">
<img src="https://github.com/thomasbriner/word2vec-Schritt-fuer-Schritt/blob/master/images/Ausschnitt_Notebook.png" width="600" height="288" title="Jupyter Notebook">
</a>



- interaktiv unter https://mybinder.org/v2/gh/thomasbriner/word2vec_Schritt_fuer_Schritt/master?filepath=word2vec_Schritt_fuer_Schritt.ipynb
